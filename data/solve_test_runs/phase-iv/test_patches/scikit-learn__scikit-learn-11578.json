{
  "edit_test_file": "sklearn/linear_model/tests/test_logistic.py",
  "test_patch": "diff --git a/sklearn/linear_model/tests/test_probabilistic_scorers.py b/sklearn/linear_model/tests/test_probabilistic_scorers.py\nnew file mode 100644\nindex 0000000..0fc22af\n--- /dev/null\n+++ b/sklearn/linear_model/tests/test_probabilistic_scorers.py\n@@ -0,0 +1,60 @@\n+import numpy as np\n+from sklearn import preprocessing, linear_model, utils\n+from sklearn.utils.testing import assert_almost_equal\n+\n+def test_probabilistic_scorers():\n+    def ovr_approach(decision_function):\n+        probs = 1. / (1. + np.exp(-decision_function))\n+        probs = probs / probs.sum(axis=1).reshape((probs.shape[0], -1))\n+        return probs\n+\n+    def score_from_probs(probs, y_bin):\n+        return (y_bin * np.log(probs)).sum(axis=1).mean()\n+\n+    np.random.seed(seed=1234)\n+\n+    samples = 200\n+    features = 5\n+    folds = 10\n+\n+    scorer = 'neg_log_loss'\n+\n+    x = np.random.random(size=(samples, features))\n+    y = np.random.choice(['a', 'b', 'c'], size=samples)\n+\n+    test = np.random.choice(range(samples), size=int(samples / float(folds)), replace=False)\n+    train = [idx for idx in range(samples) if idx not in test]\n+\n+    lb = preprocessing.label.LabelBinarizer()\n+    lb.fit(y[test])\n+    y_bin = lb.transform(y[test])\n+\n+    coefs, _, scores, _ = linear_model.logistic._log_reg_scoring_path(\n+        x, y, train, test, fit_intercept=True, scoring=scorer, multi_class='multinomial'\n+    )\n+\n+    c_index = 0\n+    coefs = coefs[c_index]\n+    scores = scores[c_index]\n+\n+    existing_log_reg = linear_model.LogisticRegression(fit_intercept=True)\n+    existing_log_reg.coef_ = coefs[:, :-1]\n+    existing_log_reg.intercept_ = coefs[:, -1]\n+\n+    existing_dec_fn = existing_log_reg.decision_function(x[test])\n+    existing_probs_builtin = existing_log_reg.predict_proba(x[test])\n+    existing_probs_ovr = ovr_approach(existing_dec_fn)\n+    existing_probs_multi = utils.extmath.softmax(existing_dec_fn)\n+\n+    new_log_reg = linear_model.LogisticRegression(fit_intercept=True, multi_class='multinomial')\n+    new_log_reg.coef_ = coefs[:, :-1]\n+    new_log_reg.intercept_ = coefs[:, -1]\n+\n+    new_dec_fn = new_log_reg.decision_function(x[test])\n+    new_probs_builtin = new_log_reg.predict_proba(x[test])\n+    new_probs_ovr = ovr_approach(new_dec_fn)\n+    new_probs_multi = utils.extmath.softmax(new_dec_fn)\n+\n+    assert_almost_equal(scores, score_from_probs(existing_probs_ovr, y_bin))\n+    assert not np.allclose(existing_probs_builtin, existing_probs_multi)\n+    assert np.allclose(new_probs_builtin, new_probs_multi)\n",
  "inverted_patch": "diff --git a/sklearn/linear_model/tests/test_probabilistic_scorers_inverted.py b/sklearn/linear_model/tests/test_probabilistic_scorers_inverted.py\nnew file mode 100644\nindex 0000000..fcc2841\n--- /dev/null\n+++ b/sklearn/linear_model/tests/test_probabilistic_scorers_inverted.py\n@@ -0,0 +1,63 @@\n+import numpy as np\n+from sklearn import preprocessing, linear_model, utils\n+from sklearn.utils.testing import assert_almost_equal\n+\n+def test_probabilistic_scorers():\n+    def ovr_approach(decision_function):\n+        probs = 1. / (1. + np.exp(-decision_function))\n+        probs = probs / probs.sum(axis=1).reshape((probs.shape[0], -1))\n+        return probs\n+\n+    def score_from_probs(probs, y_bin):\n+        return (y_bin * np.log(probs)).sum(axis=1).mean()\n+\n+    np.random.seed(seed=1234)\n+\n+    samples = 200\n+    features = 5\n+    folds = 10\n+\n+    scorer = 'neg_log_loss'\n+\n+    x = np.random.random(size=(samples, features))\n+    y = np.random.choice(['a', 'b', 'c'], size=samples)\n+\n+    test = np.random.choice(range(samples), size=int(samples / float(folds)), replace=False)\n+    train = [idx for idx in range(samples) if idx not in test]\n+\n+    lb = preprocessing.label.LabelBinarizer()\n+    lb.fit(y[test])\n+    y_bin = lb.transform(y[test])\n+\n+    coefs, _, scores, _ = linear_model.logistic._log_reg_scoring_path(\n+        x, y, train, test, fit_intercept=True, scoring=scorer, multi_class='multinomial'\n+    )\n+\n+    c_index = 0\n+    coefs = coefs[c_index]\n+    scores = scores[c_index]\n+\n+    existing_log_reg = linear_model.LogisticRegression(fit_intercept=True)\n+    existing_log_reg.coef_ = coefs[:, :-1]\n+    existing_log_reg.intercept_ = coefs[:, -1]\n+\n+    existing_dec_fn = existing_log_reg.decision_function(x[test])\n+    existing_probs_builtin = existing_log_reg.predict_proba(x[test])\n+    existing_probs_ovr = ovr_approach(existing_dec_fn)\n+    existing_probs_multi = utils.extmath.softmax(existing_dec_fn)\n+\n+    new_log_reg = linear_model.LogisticRegression(fit_intercept=True, multi_class='multinomial')\n+    new_log_reg.coef_ = coefs[:, :-1]\n+    new_log_reg.intercept_ = coefs[:, -1]\n+\n+    new_dec_fn = new_log_reg.decision_function(x[test])\n+    new_probs_builtin = new_log_reg.predict_proba(x[test])\n+    new_probs_ovr = ovr_approach(new_dec_fn)\n+    new_probs_multi = utils.extmath.softmax(new_dec_fn)\n+\n+    assert_almost_equal(scores, score_from_probs(existing_probs_ovr, y_bin))\n+    assert not np.allclose(existing_probs_builtin, existing_probs_multi)\n+    \n+    # Altered assertion to fail when the issue is observed\n+    if np.allclose(new_probs_builtin, new_probs_multi):\n+        raise AssertionError(\"__BUG__HERE__\")\n"
}