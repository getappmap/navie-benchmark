{
  "instance_id": "scikit-learn__scikit-learn-11578",
  "edit_test_file": "sklearn/linear_model/tests/test_logistic.py",
  "code_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex e4ea696..faefd80 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -922,7 +922,7 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n         check_input=False, max_squared_sum=max_squared_sum,\n         sample_weight=sample_weight)\n \n-    log_reg = LogisticRegression(fit_intercept=fit_intercept)\n+    log_reg = LogisticRegression(fit_intercept=fit_intercept, multi_class=multi_class)\n \n     # The score method of Logistic Regression has a classes_ attribute.\n     if multi_class == 'ovr':\n",
  "test_patch": "diff --git a/sklearn/linear_model/tests/test_probabilistic_scorers.py b/sklearn/linear_model/tests/test_probabilistic_scorers.py\nnew file mode 100644\nindex 0000000..0fc22af\n--- /dev/null\n+++ b/sklearn/linear_model/tests/test_probabilistic_scorers.py\n@@ -0,0 +1,60 @@\n+import numpy as np\n+from sklearn import preprocessing, linear_model, utils\n+from sklearn.utils.testing import assert_almost_equal\n+\n+def test_probabilistic_scorers():\n+    def ovr_approach(decision_function):\n+        probs = 1. / (1. + np.exp(-decision_function))\n+        probs = probs / probs.sum(axis=1).reshape((probs.shape[0], -1))\n+        return probs\n+\n+    def score_from_probs(probs, y_bin):\n+        return (y_bin * np.log(probs)).sum(axis=1).mean()\n+\n+    np.random.seed(seed=1234)\n+\n+    samples = 200\n+    features = 5\n+    folds = 10\n+\n+    scorer = 'neg_log_loss'\n+\n+    x = np.random.random(size=(samples, features))\n+    y = np.random.choice(['a', 'b', 'c'], size=samples)\n+\n+    test = np.random.choice(range(samples), size=int(samples / float(folds)), replace=False)\n+    train = [idx for idx in range(samples) if idx not in test]\n+\n+    lb = preprocessing.label.LabelBinarizer()\n+    lb.fit(y[test])\n+    y_bin = lb.transform(y[test])\n+\n+    coefs, _, scores, _ = linear_model.logistic._log_reg_scoring_path(\n+        x, y, train, test, fit_intercept=True, scoring=scorer, multi_class='multinomial'\n+    )\n+\n+    c_index = 0\n+    coefs = coefs[c_index]\n+    scores = scores[c_index]\n+\n+    existing_log_reg = linear_model.LogisticRegression(fit_intercept=True)\n+    existing_log_reg.coef_ = coefs[:, :-1]\n+    existing_log_reg.intercept_ = coefs[:, -1]\n+\n+    existing_dec_fn = existing_log_reg.decision_function(x[test])\n+    existing_probs_builtin = existing_log_reg.predict_proba(x[test])\n+    existing_probs_ovr = ovr_approach(existing_dec_fn)\n+    existing_probs_multi = utils.extmath.softmax(existing_dec_fn)\n+\n+    new_log_reg = linear_model.LogisticRegression(fit_intercept=True, multi_class='multinomial')\n+    new_log_reg.coef_ = coefs[:, :-1]\n+    new_log_reg.intercept_ = coefs[:, -1]\n+\n+    new_dec_fn = new_log_reg.decision_function(x[test])\n+    new_probs_builtin = new_log_reg.predict_proba(x[test])\n+    new_probs_ovr = ovr_approach(new_dec_fn)\n+    new_probs_multi = utils.extmath.softmax(new_dec_fn)\n+\n+    assert_almost_equal(scores, score_from_probs(existing_probs_ovr, y_bin))\n+    assert not np.allclose(existing_probs_builtin, existing_probs_multi)\n+    assert np.allclose(new_probs_builtin, new_probs_multi)\n",
  "test_inverted_patch": "diff --git a/sklearn/linear_model/tests/test_probabilistic_scorers_inverted.py b/sklearn/linear_model/tests/test_probabilistic_scorers_inverted.py\nnew file mode 100644\nindex 0000000..fcc2841\n--- /dev/null\n+++ b/sklearn/linear_model/tests/test_probabilistic_scorers_inverted.py\n@@ -0,0 +1,63 @@\n+import numpy as np\n+from sklearn import preprocessing, linear_model, utils\n+from sklearn.utils.testing import assert_almost_equal\n+\n+def test_probabilistic_scorers():\n+    def ovr_approach(decision_function):\n+        probs = 1. / (1. + np.exp(-decision_function))\n+        probs = probs / probs.sum(axis=1).reshape((probs.shape[0], -1))\n+        return probs\n+\n+    def score_from_probs(probs, y_bin):\n+        return (y_bin * np.log(probs)).sum(axis=1).mean()\n+\n+    np.random.seed(seed=1234)\n+\n+    samples = 200\n+    features = 5\n+    folds = 10\n+\n+    scorer = 'neg_log_loss'\n+\n+    x = np.random.random(size=(samples, features))\n+    y = np.random.choice(['a', 'b', 'c'], size=samples)\n+\n+    test = np.random.choice(range(samples), size=int(samples / float(folds)), replace=False)\n+    train = [idx for idx in range(samples) if idx not in test]\n+\n+    lb = preprocessing.label.LabelBinarizer()\n+    lb.fit(y[test])\n+    y_bin = lb.transform(y[test])\n+\n+    coefs, _, scores, _ = linear_model.logistic._log_reg_scoring_path(\n+        x, y, train, test, fit_intercept=True, scoring=scorer, multi_class='multinomial'\n+    )\n+\n+    c_index = 0\n+    coefs = coefs[c_index]\n+    scores = scores[c_index]\n+\n+    existing_log_reg = linear_model.LogisticRegression(fit_intercept=True)\n+    existing_log_reg.coef_ = coefs[:, :-1]\n+    existing_log_reg.intercept_ = coefs[:, -1]\n+\n+    existing_dec_fn = existing_log_reg.decision_function(x[test])\n+    existing_probs_builtin = existing_log_reg.predict_proba(x[test])\n+    existing_probs_ovr = ovr_approach(existing_dec_fn)\n+    existing_probs_multi = utils.extmath.softmax(existing_dec_fn)\n+\n+    new_log_reg = linear_model.LogisticRegression(fit_intercept=True, multi_class='multinomial')\n+    new_log_reg.coef_ = coefs[:, :-1]\n+    new_log_reg.intercept_ = coefs[:, -1]\n+\n+    new_dec_fn = new_log_reg.decision_function(x[test])\n+    new_probs_builtin = new_log_reg.predict_proba(x[test])\n+    new_probs_ovr = ovr_approach(new_dec_fn)\n+    new_probs_multi = utils.extmath.softmax(new_dec_fn)\n+\n+    assert_almost_equal(scores, score_from_probs(existing_probs_ovr, y_bin))\n+    assert not np.allclose(existing_probs_builtin, existing_probs_multi)\n+    \n+    # Altered assertion to fail when the issue is observed\n+    if np.allclose(new_probs_builtin, new_probs_multi):\n+        raise AssertionError(\"__BUG__HERE__\")\n",
  "num_sent_chars": 4781374,
  "num_received_chars": 45966,
  "elapsed_time": 447.41258120536804,
  "lint_repair_count": 7,
  "test_generation_attempts": 0,
  "code_generation_attempts": 9,
  "pass_to_pass": true,
  "pass_to_fail": true,
  "fail_to_pass": false,
  "code_patch_score": 2,
  "appmap_data_test_status": null,
  "appmap_data_file_count": null,
  "appmap_data_context_size": null
}