{
  "instance_id": "scikit-learn__scikit-learn-11578",
  "edit_test_file": "sklearn/tests/test_multioutput.py",
  "code_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex e4ea696..faefd80 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -922,7 +922,7 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n         check_input=False, max_squared_sum=max_squared_sum,\n         sample_weight=sample_weight)\n \n-    log_reg = LogisticRegression(fit_intercept=fit_intercept)\n+    log_reg = LogisticRegression(fit_intercept=fit_intercept, multi_class=multi_class)\n \n     # The score method of Logistic Regression has a classes_ attribute.\n     if multi_class == 'ovr':\n",
  "test_patch": "diff --git a/sklearn/tests/test_logistic_regression_scorer_issue.py b/sklearn/tests/test_logistic_regression_scorer_issue.py\nnew file mode 100644\nindex 0000000..5ae786b\n--- /dev/null\n+++ b/sklearn/tests/test_logistic_regression_scorer_issue.py\n@@ -0,0 +1,61 @@\n+import numpy as np\n+from sklearn import preprocessing, linear_model, utils\n+from sklearn.utils.testing import assert_almost_equal\n+\n+def ovr_approach(decision_function):\n+    probs = 1. / (1. + np.exp(-decision_function))\n+    probs = probs / probs.sum(axis=1).reshape((probs.shape[0], -1))\n+    return probs\n+\n+def score_from_probs(probs, y_bin):\n+    return (y_bin * np.log(probs)).sum(axis=1).mean()\n+\n+def test_logistic_regression_scorer_issue():\n+    np.random.seed(seed=1234)\n+\n+    samples = 200\n+    features = 5\n+    folds = 10\n+\n+    scorer = 'neg_log_loss'\n+\n+    x = np.random.random(size=(samples, features))\n+    y = np.random.choice(['a', 'b', 'c'], size=samples)\n+\n+    test = np.random.choice(range(samples), size=int(samples / float(folds)), replace=False)\n+    train = [idx for idx in range(samples) if idx not in test]\n+\n+    lb = preprocessing.label.LabelBinarizer()\n+    lb.fit(y[test])\n+    y_bin = lb.transform(y[test])\n+\n+    coefs, _, scores, _ = linear_model.logistic._log_reg_scoring_path(\n+        x, y, train, test, fit_intercept=True, scoring=scorer, multi_class='multinomial'\n+    )\n+\n+    c_index = 0\n+    coefs = coefs[c_index]\n+    scores = scores[c_index]\n+\n+    existing_log_reg = linear_model.LogisticRegression(fit_intercept=True)\n+    existing_log_reg.coef_ = coefs[:, :-1]\n+    existing_log_reg.intercept_ = coefs[:, -1]\n+\n+    existing_dec_fn = existing_log_reg.decision_function(x[test])\n+    existing_probs_builtin = existing_log_reg.predict_proba(x[test])\n+    existing_probs_ovr = ovr_approach(existing_dec_fn)\n+    existing_probs_multi = utils.extmath.softmax(existing_dec_fn)\n+\n+    new_log_reg = linear_model.LogisticRegression(fit_intercept=True, multi_class='multinomial')\n+    new_log_reg.coef_ = coefs[:, :-1]\n+    new_log_reg.intercept_ = coefs[:, -1]\n+\n+    new_dec_fn = new_log_reg.decision_function(x[test])\n+    new_probs_builtin = new_log_reg.predict_proba(x[test])\n+    new_probs_ovr = ovr_approach(new_dec_fn)\n+    new_probs_multi = utils.extmath.softmax(new_dec_fn)\n+\n+    assert_almost_equal(scores, score_from_probs(existing_probs_ovr, y_bin))\n+    assert not (existing_probs_builtin == existing_probs_multi).any()\n+    assert not (new_probs_builtin == new_probs_ovr).all()\n+    assert (new_probs_builtin == new_probs_multi).any()\n\\ No newline at end of file\n",
  "test_inverted_patch": "diff --git a/sklearn/tests/test_logistic_regression_scorer_issue_inverted.py b/sklearn/tests/test_logistic_regression_scorer_issue_inverted.py\nnew file mode 100644\nindex 0000000..b7a4a19\n--- /dev/null\n+++ b/sklearn/tests/test_logistic_regression_scorer_issue_inverted.py\n@@ -0,0 +1,61 @@\n+import numpy as np\n+from sklearn import preprocessing, linear_model, utils\n+from sklearn.utils.testing import assert_almost_equal\n+\n+def ovr_approach(decision_function):\n+    probs = 1. / (1. + np.exp(-decision_function))\n+    probs = probs / probs.sum(axis=1).reshape((probs.shape[0], -1))\n+    return probs\n+\n+def score_from_probs(probs, y_bin):\n+    return (y_bin * np.log(probs)).sum(axis=1).mean()\n+\n+def test_logistic_regression_scorer_issue():\n+    np.random.seed(seed=1234)\n+\n+    samples = 200\n+    features = 5\n+    folds = 10\n+\n+    scorer = 'neg_log_loss'\n+\n+    x = np.random.random(size=(samples, features))\n+    y = np.random.choice(['a', 'b', 'c'], size=samples)\n+\n+    test = np.random.choice(range(samples), size=int(samples / float(folds)), replace=False)\n+    train = [idx for idx in range(samples) if idx not in test]\n+\n+    lb = preprocessing.label.LabelBinarizer()\n+    lb.fit(y[test])\n+    y_bin = lb.transform(y[test])\n+\n+    coefs, _, scores, _ = linear_model.logistic._log_reg_scoring_path(\n+        x, y, train, test, fit_intercept=True, scoring=scorer, multi_class='multinomial'\n+    )\n+\n+    c_index = 0\n+    coefs = coefs[c_index]\n+    scores = scores[c_index]\n+\n+    existing_log_reg = linear_model.LogisticRegression(fit_intercept=True)\n+    existing_log_reg.coef_ = coefs[:, :-1]\n+    existing_log_reg.intercept_ = coefs[:, -1]\n+\n+    existing_dec_fn = existing_log_reg.decision_function(x[test])\n+    existing_probs_builtin = existing_log_reg.predict_proba(x[test])\n+    existing_probs_ovr = ovr_approach(existing_dec_fn)\n+    existing_probs_multi = utils.extmath.softmax(existing_dec_fn)\n+\n+    new_log_reg = linear_model.LogisticRegression(fit_intercept=True, multi_class='multinomial')\n+    new_log_reg.coef_ = coefs[:, :-1]\n+    new_log_reg.intercept_ = coefs[:, -1]\n+\n+    new_dec_fn = new_log_reg.decision_function(x[test])\n+    new_probs_builtin = new_log_reg.predict_proba(x[test])\n+    new_probs_ovr = ovr_approach(new_dec_fn)\n+    new_probs_multi = utils.extmath.softmax(new_dec_fn)\n+\n+    assert_almost_equal(scores, score_from_probs(existing_probs_ovr, y_bin))\n+    assert not (existing_probs_builtin == existing_probs_multi).any()\n+    assert not (new_probs_builtin == new_probs_ovr).all()\n+    assert not (new_probs_builtin == new_probs_multi).any(), \"__BUG__HERE__\"\n\\ No newline at end of file\n",
  "num_sent_chars": 1167507,
  "num_received_chars": 30186,
  "elapsed_time": 248.9039008617401,
  "lint_repair_count": 0,
  "test_generation_attempts": 0,
  "code_generation_attempts": 6,
  "pass_to_pass": true,
  "pass_to_fail": true,
  "fail_to_pass": false,
  "code_patch_score": 2,
  "appmap_data_test_status": null,
  "appmap_data_file_count": null,
  "appmap_data_context_size": null
}