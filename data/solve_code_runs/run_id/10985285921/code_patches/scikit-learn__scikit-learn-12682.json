{
  "instance_id": "scikit-learn__scikit-learn-12682",
  "edit_test_file": "sklearn/linear_model/tests/test_coordinate_descent.py",
  "code_patch": "diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py\nindex a318c95..9bcdfda 100644\n--- a/sklearn/decomposition/dict_learning.py\n+++ b/sklearn/decomposition/dict_learning.py\n@@ -900,7 +900,8 @@ class SparseCodingMixin(TransformerMixin):\n             X, self.components_, algorithm=self.transform_algorithm,\n             n_nonzero_coefs=self.transform_n_nonzero_coefs,\n             alpha=self.transform_alpha, n_jobs=self.n_jobs,\n-            positive=self.positive_code)\n+            positive=self.positive_code,\n+            **(self.lasso_params if self.transform_algorithm == 'lasso_cd' else {}))\n \n         if self.split_sign:\n             # feature vector is split into a positive and negative side\n@@ -944,6 +945,10 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):\n         threshold: squashes to zero all coefficients less than alpha from\n         the projection ``dictionary * X'``\n \n+    lasso_params : dict, optional\n+        Additional parameters to pass to the Lasso solver when using\n+        `lasso_cd` algorithm. This can include `max_iter`, `tol`, etc.\n+\n     transform_n_nonzero_coefs : int, ``0.1 * n_features`` by default\n         Number of nonzero coefficients to target in each column of the\n         solution. This is only used by `algorithm='lars'` and `algorithm='omp'`\n@@ -991,13 +996,15 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):\n \n     def __init__(self, dictionary, transform_algorithm='omp',\n                  transform_n_nonzero_coefs=None, transform_alpha=None,\n-                 split_sign=False, n_jobs=None, positive_code=False):\n+                 split_sign=False, n_jobs=None, positive_code=False,\n+                 lasso_params=None):\n         self._set_sparse_coding_params(dictionary.shape[0],\n                                        transform_algorithm,\n                                        transform_n_nonzero_coefs,\n                                        transform_alpha, split_sign, n_jobs,\n                                        positive_code)\n         self.components_ = dictionary\n+        self.lasso_params = lasso_params if lasso_params is not None else {}\n \n     def fit(self, X, y=None):\n         \"\"\"Do nothing and return the estimator unchanged\n",
  "test_patch": "diff --git a/sklearn/linear_model/tests/test_sparsecoder_lasso.py b/sklearn/linear_model/tests/test_sparsecoder_lasso.py\nnew file mode 100644\nindex 0000000..3124b77\n--- /dev/null\n+++ b/sklearn/linear_model/tests/test_sparsecoder_lasso.py\n@@ -0,0 +1,21 @@\n+import numpy as np\n+import pytest\n+from sklearn.decomposition import SparseCoder\n+from sklearn.exceptions import ConvergenceWarning\n+from sklearn.utils._unittest_backport import TestCase\n+\n+class TestSparseCoderLasso(TestCase):\n+    def test_sparse_coder_lasso_convergence_warning(self):\n+        # Create a random dictionary and data\n+        rng = np.random.RandomState(0)\n+        n_components, n_features = 12, 8\n+        V = rng.randn(n_components, n_features)\n+        V /= np.sum(V ** 2, axis=1)[:, np.newaxis]\n+        X = rng.randn(10, n_features)\n+\n+        # Initialize SparseCoder with lasso_cd algorithm\n+        coder = SparseCoder(dictionary=V, transform_algorithm='lasso_cd', transform_alpha=0.001)\n+\n+        # Check for convergence warning\n+        with pytest.warns(ConvergenceWarning, match=\"Objective did not converge\"):\n+            coder.transform(X)\n",
  "test_inverted_patch": null,
  "num_sent_chars": 6886060,
  "num_received_chars": 152884,
  "elapsed_time": 785.798721075058,
  "lint_repair_count": 9,
  "test_generation_attempts": 3,
  "code_generation_attempts": 9,
  "pass_to_pass": true,
  "pass_to_fail": false,
  "fail_to_pass": false,
  "code_patch_score": 1,
  "appmap_data_test_status": null,
  "appmap_data_file_count": null,
  "appmap_data_context_size": null
}