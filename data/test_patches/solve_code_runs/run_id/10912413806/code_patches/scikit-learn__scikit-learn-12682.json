{
  "instance_id": "scikit-learn__scikit-learn-12682",
  "edit_test_file": "sklearn/linear_model/tests/test_coordinate_descent.py",
  "code_patch": "diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py\nindex a318c95..4cd0cf6 100644\n--- a/sklearn/decomposition/dict_learning.py\n+++ b/sklearn/decomposition/dict_learning.py\n@@ -900,7 +900,8 @@ class SparseCodingMixin(TransformerMixin):\n             X, self.components_, algorithm=self.transform_algorithm,\n             n_nonzero_coefs=self.transform_n_nonzero_coefs,\n             alpha=self.transform_alpha, n_jobs=self.n_jobs,\n-            positive=self.positive_code)\n+            positive=self.positive_code,\n+            max_iter=self.lasso_max_iter if self.transform_algorithm == 'lasso_cd' else None)\n \n         if self.split_sign:\n             # feature vector is split into a positive and negative side\n@@ -935,6 +936,10 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):\n     transform_algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp', \\\n     'threshold'}\n         Algorithm used to transform the data:\n+\n+    lasso_max_iter : int, optional\n+        Maximum number of iterations for the Lasso solver when using\n+        `algorithm='lasso_cd'`. Defaults to 1000.\n         lars: uses the least angle regression method (linear_model.lars_path)\n         lasso_lars: uses Lars to compute the Lasso solution\n         lasso_cd: uses the coordinate descent method to compute the\n@@ -991,13 +996,15 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):\n \n     def __init__(self, dictionary, transform_algorithm='omp',\n                  transform_n_nonzero_coefs=None, transform_alpha=None,\n-                 split_sign=False, n_jobs=None, positive_code=False):\n+                 split_sign=False, n_jobs=None, positive_code=False,\n+                 lasso_max_iter=1000):\n         self._set_sparse_coding_params(dictionary.shape[0],\n                                        transform_algorithm,\n                                        transform_n_nonzero_coefs,\n                                        transform_alpha, split_sign, n_jobs,\n                                        positive_code)\n         self.components_ = dictionary\n+        self.lasso_max_iter = lasso_max_iter\n \n     def fit(self, X, y=None):\n         \"\"\"Do nothing and return the estimator unchanged\n",
  "test_patch": "diff --git a/sklearn/linear_model/tests/test_sparse_coder.py b/sklearn/linear_model/tests/test_sparse_coder.py\nnew file mode 100644\nindex 0000000..6a3d927\n--- /dev/null\n+++ b/sklearn/linear_model/tests/test_sparse_coder.py\n@@ -0,0 +1,17 @@\n+import numpy as np\n+from sklearn.decomposition import SparseCoder\n+from sklearn.linear_model import Lasso\n+from sklearn.exceptions import ConvergenceWarning\n+from sklearn.utils.testing import assert_warns\n+\n+def test_sparse_coder_lasso_convergence_warning():\n+    # Create a dataset that will not converge with default max_iter\n+    rng = np.random.RandomState(0)\n+    n_components, n_features = 12, 8\n+    V = rng.randn(n_components, n_features)\n+    V /= np.sum(V ** 2, axis=1)[:, np.newaxis]\n+    X = rng.randn(10, n_features)\n+\n+    # Test that a ConvergenceWarning is raised due to max_iter not being exposed\n+    coder = SparseCoder(dictionary=V, transform_algorithm='lasso_cd', transform_alpha=0.001)\n+    assert_warns(ConvergenceWarning, coder.transform, X)\n\\ No newline at end of file\n",
  "test_inverted_patch": "diff --git a/sklearn/linear_model/tests/test_sparse_coder_inverted.py b/sklearn/linear_model/tests/test_sparse_coder_inverted.py\nnew file mode 100644\nindex 0000000..35f3af6\n--- /dev/null\n+++ b/sklearn/linear_model/tests/test_sparse_coder_inverted.py\n@@ -0,0 +1,19 @@\n+import numpy as np\n+from sklearn.decomposition import SparseCoder\n+from sklearn.linear_model import Lasso\n+from sklearn.exceptions import ConvergenceWarning\n+import pytest\n+\n+def test_sparse_coder_lasso_convergence_warning():\n+    # Create a dataset that will not converge with default max_iter\n+    rng = np.random.RandomState(0)\n+    n_components, n_features = 12, 8\n+    V = rng.randn(n_components, n_features)\n+    V /= np.sum(V ** 2, axis=1)[:, np.newaxis]\n+    X = rng.randn(10, n_features)\n+\n+    # Test that a ConvergenceWarning is raised due to max_iter not being exposed\n+    coder = SparseCoder(dictionary=V, transform_algorithm='lasso_cd', transform_alpha=0.001)\n+    \n+    with pytest.raises(ConvergenceWarning, match=\"__BUG__HERE__\"):\n+        coder.transform(X)\n\\ No newline at end of file\n",
  "num_sent_chars": 2866689,
  "num_received_chars": 105325,
  "elapsed_time": 915.7572796344757,
  "lint_repair_count": 10,
  "test_generation_attempts": 0,
  "code_generation_attempts": 9,
  "pass_to_pass": true,
  "pass_to_fail": false,
  "fail_to_pass": false,
  "code_patch_score": 1,
  "appmap_data_test_status": null,
  "appmap_data_file_count": null,
  "appmap_data_context_size": null
}