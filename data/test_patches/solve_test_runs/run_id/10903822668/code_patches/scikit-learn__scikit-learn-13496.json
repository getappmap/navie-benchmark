{
  "instance_id": "scikit-learn__scikit-learn-13496",
  "edit_test_file": "sklearn/ensemble/tests/test_forest.py",
  "code_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 8a1bd36..7a21cdd 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -111,6 +111,11 @@ class IsolationForest(BaseBagging, OutlierMixin):\n            ``behaviour`` parameter will be deprecated in 0.22 and removed in\n            0.24.\n \n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to `fit`\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. This is useful for building the forest incrementally.\n+\n     random_state : int, RandomState instance or None, optional (default=None)\n         If int, random_state is the seed used by the random number generator;\n         If RandomState instance, random_state is the random number generator;\n@@ -173,7 +178,8 @@ class IsolationForest(BaseBagging, OutlierMixin):\n                  n_jobs=None,\n                  behaviour='old',\n                  random_state=None,\n-                 verbose=0):\n+                 verbose=0,\n+                 warm_start=False):\n         super().__init__(\n             base_estimator=ExtraTreeRegressor(\n                 max_features=1,\n@@ -187,7 +193,8 @@ class IsolationForest(BaseBagging, OutlierMixin):\n             max_features=max_features,\n             n_jobs=n_jobs,\n             random_state=random_state,\n-            verbose=verbose)\n+            verbose=verbose,\n+            warm_start=warm_start)\n \n         self.behaviour = behaviour\n         self.contamination = contamination\n",
  "test_patch": "diff --git a/sklearn/ensemble/tests/test_isolation_forest_warm_start.py b/sklearn/ensemble/tests/test_isolation_forest_warm_start.py\nnew file mode 100644\nindex 0000000..99667c1\n--- /dev/null\n+++ b/sklearn/ensemble/tests/test_isolation_forest_warm_start.py\n@@ -0,0 +1,25 @@\n+import numpy as np\n+from sklearn.ensemble import IsolationForest\n+from sklearn.utils.testing import assert_raises\n+\n+def test_isolation_forest_warm_start():\n+    # Generate random data\n+    rng = np.random.RandomState(42)\n+    X = rng.randn(100, 2)\n+\n+    # Initialize IsolationForest without warm_start\n+    iso_forest = IsolationForest(n_estimators=10, random_state=0)\n+    iso_forest.fit(X)\n+    initial_decision_function = iso_forest.decision_function(X)\n+\n+    # Attempt to enable warm_start and increment n_estimators\n+    # This should raise a ValueError because warm_start is not exposed\n+    assert_raises(ValueError, iso_forest.set_params, warm_start=True, n_estimators=20)\n+\n+    # Fit again to check if the decision function changes\n+    iso_forest.fit(X)\n+    new_decision_function = iso_forest.decision_function(X)\n+\n+    # Check if the decision function remains the same\n+    assert np.array_equal(initial_decision_function, new_decision_function), \\\n+        \"Decision function should not change when refitting without warm_start\"\n",
  "test_inverted_patch": "diff --git a/sklearn/ensemble/tests/test_isolation_forest_warm_start_inverted.py b/sklearn/ensemble/tests/test_isolation_forest_warm_start_inverted.py\nnew file mode 100644\nindex 0000000..119137d\n--- /dev/null\n+++ b/sklearn/ensemble/tests/test_isolation_forest_warm_start_inverted.py\n@@ -0,0 +1,26 @@\n+import numpy as np\n+from sklearn.ensemble import IsolationForest\n+import pytest\n+\n+def test_isolation_forest_warm_start():\n+    # Generate random data\n+    rng = np.random.RandomState(42)\n+    X = rng.randn(100, 2)\n+\n+    # Initialize IsolationForest without warm_start\n+    iso_forest = IsolationForest(n_estimators=10, random_state=0)\n+    iso_forest.fit(X)\n+    initial_decision_function = iso_forest.decision_function(X)\n+\n+    # Attempt to enable warm_start and increment n_estimators\n+    # This should raise a ValueError because warm_start is not exposed\n+    with pytest.raises(ValueError):\n+        iso_forest.set_params(warm_start=True, n_estimators=20)\n+\n+    # Fit again to check if the decision function changes\n+    iso_forest.fit(X)\n+    new_decision_function = iso_forest.decision_function(X)\n+\n+    # Check if the decision function remains the same\n+    if np.array_equal(initial_decision_function, new_decision_function):\n+        raise AssertionError(\"__BUG__HERE__\")\n\\ No newline at end of file\n",
  "num_sent_chars": 1909749,
  "num_received_chars": 83896,
  "elapsed_time": 858.1785001754761,
  "lint_repair_count": 7,
  "test_generation_attempts": 2,
  "code_generation_attempts": 9,
  "pass_to_pass": true,
  "pass_to_fail": true,
  "fail_to_pass": false,
  "code_patch_score": 2,
  "appmap_data_test_status": null,
  "appmap_data_file_count": null,
  "appmap_data_context_size": null
}